---

global:
  imagePullPolicy: Always

replicaCount: 1

# See `kubectl explain deployment.spec.strategy` for more
# ref: https://kubernetes.io/docs/concepts/workloads/controllers/deployment/#strategy
deploymentStrategy:
  type: Recreate

deploymentType: deployment
# deploymentType: statefulset

image:
  registry: ghcr.io
  repository: edgecomllc
  name: eupf
  # Overrides the image tag whose default is the chart appVersion.
  tag: 0.6.4
  pullPolicy: IfNotPresent

fullnameOverride: "eupf"

# Override default container command
command:
  - /bin/sh
  - -c
  - |
      set -x ; \
      export PFCP_IP=$(hostname -i); \
      mkdir /etc/iproute2 ; echo "111 fromn3gtp" >> /etc/iproute2/rt_tables ; \
      sysctl -w net.ipv4.ip_forward=1 ; \ 
      /app/bin/eupf --paddr ${PFCP_IP}:8805 --n3addr 192.168.252.3 --iface access --iface core 
# Override default container args
args:
  - --config
  - /app/conf/config.yml


initContainers: []
  # - name: run-db-migrations
  #   # if "" then uses default image for this chart
  #   image: ""
  #   command:
  #     - /bin/sh
  #     - -ec
  #     - |
  #       python3 manage.py migrate
  # - name: run-something
  #   image: ""
  #   command:
  #     - /bin/sh
  #     - -ec
  #     - |
  #       echo "start something"

imagePullSecrets: []
nameOverride: ""

# Additional environment variables
env:
  UPF_PFCP_NODE_ID: 192.168.250.3
  UPF_N3_ADDRESS: 10.100.50.233

# create config maps
configMaps:
  config:
    data:
      config.yml: |
        interface_name: [access, eth0, core]
        api_address: :8080
        pfcp_address: PFCP_ADDRESS:8805
        metrics_address: :9090
        n3_address: 192.168.252.3

# volumes
volumes:
  - name: sys
    hostPath:
      path: /sys
  - name: config
    configMap:
      name: eupf-config
      defaultMode: 420
      items:
        - key: config.yml
          mode: 493
          path: config.yml

# volume mounts
volumeMounts:
  - name: sys
    mountPath: /sys
    readOnly:  true
  - name: config
    mountPath: /app/conf

hostNetwork: false

xdpProgrammInstall:
  enabled: false
  securityContext:
    capabilities:
      add:
        - NET_ADMIN
        - BPF
    privileged: true
    runAsNonRoot: false
  env:
    - name: POD_N6_IP
      value: 10.100.100.12
  command:
    - /bin/sh
    - -c
    - |
      apk add iproute2; \
      echo "starting"; \
      i=0; IFACE_NAME=""; \
      while [ -z "$IFACE_NAME" ]; \
      do \
        echo "check $i: searching interface name"; sleep 1; \
        IFACE_NAME=$(ip route list ${POD_N6_IP} | awk '{print $3}'); \
        i=$((i+1)); \
      done ;\
      echo "done: current interface name is ${IFACE_NAME}" ;\
      set -x ;\
      ls -alh /app ;\
      ip link set dev ${IFACE_NAME} xdpdrv obj /app/zeroentrypoint_bpf.o sec xdp/upf_zero_entrypoint

bird:
  enabled: false
  image: docker.io/edgecom/bird:0.0.4
  env:
    BIRD_ROUTER_ID: $(MY_POD_IP)
    BIRD_LOCAL_AS: 65000
    BIRD_LOCAL_PREFIX: 10.45.0.0/16
    BIRD_NEIGHBOR_IP: $(MY_NODE_IP)
    BIRD_NEIGHBOR_AS: 64512
  service:
    enabled: false
    type: ClusterIP
    port: 179
  ports:
    - name: bgp
      containerPort: 179
      protocol: TCP
  resources:
    limits:
      cpu: 100m
      memory: 128Mi
    requests:
      cpu: 100m
      memory: 128Mi
  livenessProbe:
    tcpSocket:
      port: bgp
    initialDelaySeconds: 5
    periodSeconds: 10
  readinessProbe:
    tcpSocket:
      port: bgp
    initialDelaySeconds: 5
    periodSeconds: 10

serviceAccount:
  # Specifies whether a service account should be created
  create: true
  # Annotations to add to the service account
  annotations: {}
  # The name of the service account to use.
  # If not set and create is true, a name is generated using the fullname template
  name: ""

metrics:
  enabled: false
  serviceMonitor:
    # Create ServiceMonitor Resource for scraping metrics using Prometheus Operator
    enabled: false
    # Namespace for the ServiceMonitor Resource (defaults to the Release Namespace)
    namespace: ""
    # Interval at which metrics should be scraped.
    # ref: https://github.com/coreos/prometheus-operator/blob/master/Documentation/api.md#endpoint
    interval: ""
    # Timeout after which the scrape is ended
    # ref: https://github.com/coreos/prometheus-operator/blob/master/Documentation/api.md#endpoint
    scrapeTimeout: ""
    # Additional labels that can be used so ServiceMonitor will be discovered by Prometheus
    labels: {}
    # Prometheus instance selector labels
    # ref: https://github.com/bitnami/charts/tree/main/bitnami/prometheus-operator#prometheus-configuration
    selector: {}
    # RelabelConfigs to apply to samples before scraping
    relabelings: []
    # MetricRelabelConfigs to apply to samples before ingestion
    metricRelabelings: []
    # Specify honorLabels parameter to add the scrape endpoint
    honorLabels: false
    # The name of the label on the target service to use as the job name in prometheus.
    jobLabel: ""
    endpoints:
      port: metrics
      path: "/metrics"

podAnnotations:
  k8s.v1.cni.cncf.io/networks: |
    [
      { "name": "access-net",
        "interface": "access",
        "ips": [ "192.168.252.3/24" ],
        "mac": "d6:a4:06:a6:45:6f",
        "dns": {}
      },
      { "name": "core-net",
        "interface": "core",
        "ips": [ "192.168.250.3/24" ],
        "mac": "f6:2b:4f:38:e8:49",
        "dns": {}
      }
    ]

network:
  master: eth0
  ipamType: static
  capabilities:
    mac: true



podSecurityContext:
  sysctls:
  - name: net.ipv4.ip_forward
    value: "1"

securityContext:
  privileged: true

extraContainerPorts:
  - name: gtpu
    containerPort: 2152
    protocol: UDP
  - name: pfcp
    containerPort: 8805
    protocol: UDP

service:
  type: ClusterIP
  port: 8080
  extraPorts:
    - port: 2152
      targetPort: gtpu
      protocol: UDP
      name: gtpu
    - port: 8805
      targetPort: pfcp
      protocol: UDP
      name: pfcp

ingress:
  enabled: false
  className: ""
  annotations: {}
    # kubernetes.io/ingress.class: nginx
    # kubernetes.io/tls-acme: "true"
  hosts:
    - host: chart-example.local
      paths:
        - path: /
          pathType: ImplementationSpecific
  tls: []
  #  - secretName: chart-example-tls
  #    hosts:
  #      - chart-example.local

resources:
  limits:
    cpu: 100m
    memory: 128Mi
  requests:
    cpu: 100m
    memory: 128Mi

startupProbe: {}
  # We usually recommend to specify probes, read https://habr.com/ru/company/nixys/blog/544288/
  # httpGet:
  #   path: /healthz
  #   port: http
  # failureThreshold: 30
  # periodSeconds: 10

nodeSelector: {}

tolerations: []

affinity: {}

# Array of extra objects to deploy with the release
# extraDeploy:
#   - apiVersion: k8s.cni.cncf.io/v1
#     kind: NetworkAttachmentDefinition
#     metadata:
#       name: "access-net"
#     spec:
#       config: |
#         {
#           "cniVersion": "0.3.1",
#           "plugins": [
#             {
#               "type": "ipvlan",
#               "capabilities": { "ips": true },
#               "master": "eth0",
#               "mode": "l2",
#               "ipam": {
#                 "type": "static"
#               }
#             }
#           ]
#         }

ui:
  enabled: false
  image:
    registry: ghcr.io
    repository: edgecomllc
    name: eupf-ui
    tag: main
    pullPolicy: Always
  env:
    API_ADDR: localhost:8080
  service:
    port: 8081
  resources:
    limits:
      cpu: 100m
      memory: 128Mi
    requests:
      cpu: 100m
      memory: 128Mi
  livenessProbe:
    httpGet:
      path: /healthz
      port: 8081
    initialDelaySeconds: 5
    periodSeconds: 10
  readinessProbe:
    httpGet:
      path: /healthz
      port: 8081
    initialDelaySeconds: 5
    periodSeconds: 10
